{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5ac6c25-9d76-4c35-99a8-567f905c31e2",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d039d9-69ec-49f9-abd0-3e09f64667d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os, sys\n",
    "\n",
    "# third party imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "assert tf.__version__.startswith('2.'), 'This tutorial assumes Tensorflow 2.0+'\n",
    "\n",
    "# local imports\n",
    "import voxelmorph as vxm\n",
    "import neurite as ne"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab67b977-801a-41e5-8f58-2c2505c7d7ab",
   "metadata": {},
   "source": [
    "# U-net Keras Backbone Model (2D Weakly Supervised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587d7701-e5b3-44f7-8a75-944da9268e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "\n",
    "def get_model(moving_image_shape, fixed_image_shape, with_label_inputs=True, up_filters=[64, 128, 256], down_filters=[256, 128, 64, 32]):\n",
    "\n",
    "    input_moving_image = keras.Input(moving_image_shape)\n",
    "    input_fixed_image = keras.Input(fixed_image_shape)\n",
    "\n",
    "    if with_label_inputs:\n",
    "        input_moving_label = keras.Input(moving_image_shape)\n",
    "        input_fixed_label = keras.Input(fixed_image_shape)\n",
    "\n",
    "    concatenate_layer = layers.Concatenate(axis=-1)([input_moving_image, input_fixed_image])\n",
    "\n",
    "    ### [First half of the network: downsampling inputs] ###\n",
    "\n",
    "    # Entry block\n",
    "    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(concatenate_layer)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    previous_block_activation = x  # Set aside residual\n",
    "\n",
    "    # Blocks 1, 2, 3 are identical apart from the feature depth.\n",
    "    for filters in up_filters:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.Conv2D(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.Conv2D(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = layers.Conv2D(filters, 1, strides=2, padding=\"same\")(\n",
    "            previous_block_activation\n",
    "        )\n",
    "        x = layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    ### [Second half of the network: upsampling inputs] ###\n",
    "\n",
    "    for filters in down_filters:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.UpSampling2D(2)(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = layers.UpSampling2D(2)(previous_block_activation)\n",
    "        residual = layers.Conv2D(filters, 1, padding=\"same\")(residual)\n",
    "        x = layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    # Add a per-pixel classification layer\n",
    "    out_ddf = layers.Conv2D(2, 3, activation=\"linear\", padding=\"same\")(x)\n",
    "\n",
    "    # Define the model\n",
    "    if with_label_inputs:\n",
    "        model = keras.Model(inputs=[input_moving_image, input_fixed_image, input_moving_label, input_fixed_label], outputs=[out_ddf])\n",
    "    else:\n",
    "        model = keras.Model(inputs=[input_moving_image, input_fixed_image], outputs=[out_ddf])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93af3618-c47a-4fda-bd7b-c6448f913dab",
   "metadata": {},
   "source": [
    "# Data Generator (2D, Weakly Supervised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35b196a-9df9-4292-b308-c49db6369ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data generator\n",
    "\n",
    "from skimage.transform import resize\n",
    "\n",
    "import nibabel as nib\n",
    "\n",
    "def resize_2d_image(image, shape):\n",
    "    image= image.squeeze()\n",
    "    resized_image = resize(image, output_shape=shape)\n",
    "    if np.amax(resized_image) == np.amin(resized_image):\n",
    "        normalised_image = resized_image\n",
    "    else:\n",
    "        normalised_image = (resized_image - np.amin(resized_image)) / (np.amax(resized_image) - np.amin(resized_image))\n",
    "    return normalised_image\n",
    "\n",
    "def train_generator_(f_path, batch_size, moving_image_shape, fixed_image_shape, with_label_inputs=True):\n",
    "    moving_images_path = os.path.join(f_path, 'us_images')\n",
    "    fixed_images_path = os.path.join(f_path, 'mr_images')\n",
    "\n",
    "    if with_label_inputs:\n",
    "        moving_labels_path = os.path.join(f_path, 'us_labels')\n",
    "        fixed_labels_path = os.path.join(f_path, 'mr_labels')\n",
    "\n",
    "    all_names = np.array(os.listdir(fixed_images_path))\n",
    "\n",
    "    while True:\n",
    "\n",
    "        batch_names = all_names[np.random.permutation(len(all_names))[:batch_size]]\n",
    "\n",
    "        moving_images_batch = np.zeros((batch_size, *moving_image_shape))\n",
    "        fixed_images_batch = np.zeros((batch_size, *fixed_image_shape))\n",
    "\n",
    "        if with_label_inputs:\n",
    "            moving_labels_batch = np.zeros((batch_size, *moving_image_shape))\n",
    "            fixed_labels_batch = np.zeros((batch_size, *fixed_image_shape))\n",
    "\n",
    "        for i, f_name in enumerate(batch_names):\n",
    "            moving_image = nib.load(os.path.join(moving_images_path, f_name)).get_fdata()\n",
    "            fixed_image = nib.load(os.path.join(fixed_images_path, f_name)).get_fdata()\n",
    "            # TAKE A SLICE FROM THE 3D IMAGE\n",
    "            slice_index_moving = moving_image.shape[0] // 2\n",
    "            slice_index_fixed = fixed_image.shape[0] // 2\n",
    "            moving_image = moving_image[slice_index_moving,:,:]\n",
    "            fixed_image = fixed_image[slice_index_fixed,:,:]\n",
    "\n",
    "            if with_label_inputs:\n",
    "                moving_label = nib.load(os.path.join(moving_labels_path, f_name)).get_fdata()\n",
    "                fixed_label = nib.load(os.path.join(fixed_labels_path, f_name)).get_fdata()\n",
    "\n",
    "                label_to_select = np.random.randint(6) #pick one label randomly for training\n",
    "\n",
    "            moving_images_batch[i] = resize_2d_image(moving_image, moving_image_shape)\n",
    "            fixed_images_batch[i] = resize_2d_image(fixed_image, fixed_image_shape)\n",
    "\n",
    "            if with_label_inputs:\n",
    "                slice_index_moving = moving_label.shape[0] // 2\n",
    "                slice_index_fixed = fixed_label.shape[0] // 2\n",
    "                moving_labels_batch[i] = resize_2d_image(moving_label[slice_index_moving, :, :, label_to_select], moving_image_shape)\n",
    "                fixed_labels_batch[i] = resize_2d_image(fixed_label[slice_index_fixed, :, :, label_to_select], fixed_image_shape)\n",
    "\n",
    "        zero_phis = np.zeros([batch_size, *moving_image_shape[:-1], 2])\n",
    "\n",
    "        if with_label_inputs:\n",
    "            inputs = (\n",
    "                tf.convert_to_tensor(moving_images_batch, dtype=tf.float32),\n",
    "                tf.convert_to_tensor(fixed_images_batch, dtype=tf.float32),\n",
    "                tf.convert_to_tensor(moving_labels_batch, dtype=tf.float32),\n",
    "                tf.convert_to_tensor(fixed_labels_batch, dtype=tf.float32)\n",
    "            )\n",
    "            outputs = (\n",
    "                tf.convert_to_tensor(fixed_images_batch, dtype=tf.float32),\n",
    "                tf.convert_to_tensor(zero_phis, dtype=tf.float32),\n",
    "                tf.convert_to_tensor(fixed_labels_batch, dtype=tf.float32),\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            inputs = (\n",
    "                tf.convert_to_tensor(moving_images_batch, dtype=tf.float32),\n",
    "                tf.convert_to_tensor(fixed_images_batch, dtype=tf.float32)\n",
    "            )\n",
    "            outputs = (\n",
    "                tf.convert_to_tensor(fixed_images_batch, dtype=tf.float32),\n",
    "                tf.convert_to_tensor(zero_phis, dtype=tf.float32)\n",
    "            )\n",
    "\n",
    "        yield inputs, outputs\n",
    "\n",
    "def test_generator(f_path, batch_size, moving_image_shape, fixed_image_shape, start_index, end_index, label_num, with_label_inputs=True):\n",
    "    moving_images_path = os.path.join(f_path, 'us_images')\n",
    "    fixed_images_path = os.path.join(f_path, 'mr_images')\n",
    "\n",
    "    if with_label_inputs:\n",
    "        moving_labels_path = os.path.join(f_path, 'us_labels')\n",
    "        fixed_labels_path = os.path.join(f_path, 'mr_labels')\n",
    "\n",
    "    all_names = np.array(os.listdir(fixed_images_path))[start_index: end_index]\n",
    "\n",
    "    if start_index and end_index is not None:\n",
    "        n_steps = int(np.floor((end_index - start_index) / batch_size))\n",
    "    else:\n",
    "        start_index = 0\n",
    "        end_index = len(all_names)\n",
    "        n_steps =int( np.floor((end_index - start_index) / batch_size))\n",
    "\n",
    "    for step in range(n_steps):\n",
    "\n",
    "        batch_names = all_names[step*batch_size:(step*batch_size)+batch_size]\n",
    "\n",
    "        moving_images_batch = np.zeros((batch_size, *moving_image_shape))\n",
    "        fixed_images_batch = np.zeros((batch_size, *fixed_image_shape))\n",
    "\n",
    "        if with_label_inputs:\n",
    "            moving_labels_batch = np.zeros((batch_size, *moving_image_shape))\n",
    "            fixed_labels_batch = np.zeros((batch_size, *fixed_image_shape))\n",
    "\n",
    "        for i, f_name in enumerate(batch_names):\n",
    "            moving_image = nib.load(os.path.join(moving_images_path, f_name)).get_fdata()\n",
    "            fixed_image = nib.load(os.path.join(fixed_images_path, f_name)).get_fdata()\n",
    "            # TAKE A SLICE FROM THE 3D IMAGE\n",
    "            slice_index_moving = moving_image.shape[0] // 2\n",
    "            slice_index_fixed = fixed_image.shape[0] // 2\n",
    "            moving_image = moving_image[slice_index_moving,:,:]\n",
    "            #print('*', moving_image.shape)\n",
    "            fixed_image = fixed_image[slice_index_fixed,:,:]\n",
    "\n",
    "            if with_label_inputs:\n",
    "                moving_label = nib.load(os.path.join(moving_labels_path, f_name)).get_fdata() # if label not available, just pass zeros\n",
    "                fixed_label = nib.load(os.path.join(fixed_labels_path, f_name)).get_fdata() # if label not available, just pass zeros\n",
    "\n",
    "                label_to_select = label_num #pick one label randomly for training\n",
    "\n",
    "            moving_images_batch[i] = resize_2d_image(moving_image, moving_image_shape)\n",
    "            fixed_images_batch[i] = resize_2d_image(fixed_image, fixed_image_shape)\n",
    "\n",
    "            if with_label_inputs:\n",
    "                slice_index_moving = moving_label.shape[0] // 2\n",
    "                slice_index_fixed = fixed_label.shape[0] // 2\n",
    "                moving_labels_batch[i] = resize_2d_image(moving_label[slice_index_moving, :, :, label_to_select], moving_image_shape)\n",
    "                fixed_labels_batch[i] = resize_2d_image(fixed_label[slice_index_fixed, :, :, label_to_select], fixed_image_shape)\n",
    "\n",
    "        zero_phis = np.zeros([batch_size, *moving_image_shape[:-1], 2])\n",
    "\n",
    "        if with_label_inputs:\n",
    "            inputs = [moving_images_batch, fixed_images_batch, moving_labels_batch, fixed_labels_batch]\n",
    "            outputs = [fixed_images_batch, zero_phis, fixed_labels_batch]\n",
    "        else:\n",
    "            inputs = [moving_images_batch, fixed_images_batch]\n",
    "            outputs = [fixed_images_batch, zero_phis]\n",
    "\n",
    "        yield (inputs, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb5bce3-3cc0-48a3-a5a4-f4d20e7ca6be",
   "metadata": {},
   "source": [
    "# Training Loop (2D, Weakly Supervised, NCC, US-MRI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b19fda5-8cb3-40b1-b3a3-79f0928c3de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train voxel morph\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train_model(last_trial=None, latest_weights=None, Verbose=False):\n",
    "    \n",
    "    for lambda_param in [0.05]:\n",
    "\n",
    "        # =============================================================================\n",
    "        # Build the backbone model\n",
    "        # =============================================================================\n",
    "    \n",
    "        moving_image_shape = (80, 80, 1)\n",
    "        fixed_image_shape = (80, 80, 1)\n",
    "        \n",
    "        model = get_model(moving_image_shape, fixed_image_shape, with_label_inputs=False)\n",
    "        \n",
    "        print('\\nBackbone model inputs and outputs:')\n",
    "        \n",
    "        print('    input shape: ', ', '.join([str(t.shape) for t in model.inputs]))\n",
    "        print('    output shape:', ', '.join([str(t.shape) for t in model.outputs]))\n",
    "        \n",
    "        # =============================================================================\n",
    "        # Build the registration network\n",
    "        # =============================================================================\n",
    "        \n",
    "        # build transformer layer\n",
    "        spatial_transformer = vxm.layers.SpatialTransformer(name='transformer')\n",
    "        \n",
    "        # extract the moving image\n",
    "        moving_image = model.input[0]\n",
    "        fixed_image = model.inputs[1]\n",
    "        input_moving_label = keras.Input(moving_image_shape, name=\"moving_label\")\n",
    "        input_fixed_label  = keras.Input(fixed_image_shape,  name=\"fixed_label\")\n",
    "        inputs=[moving_image, fixed_image, input_moving_label, input_fixed_label]\n",
    "        \n",
    "        # extract ddf\n",
    "        ddf = model.outputs[0]\n",
    "        \n",
    "        # warp the moving image with the transformer using network-predicted ddf\n",
    "        moved_image = spatial_transformer([moving_image, ddf])\n",
    "        moved_label = spatial_transformer([input_moving_label, ddf])\n",
    "        fixed_label = spatial_transformer([input_moving_label, ddf])*0 + input_fixed_label\n",
    "        \n",
    "        outputs = [moved_image, ddf, moved_label]\n",
    "        \n",
    "        registration_model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "        \n",
    "        print('\\nRegistration network inputs and outputs:')\n",
    "        \n",
    "        print('    input shape: ', ', '.join([str(t.shape) for t in registration_model.inputs]))\n",
    "        print('    output shape:', ', '.join([str(t.shape) for t in registration_model.outputs]))\n",
    "    \n",
    "        losses = [vxm.losses.NCC().loss, vxm.losses.Grad('l2').loss, vxm.losses.Dice().loss]\n",
    "        loss_weights = [0, lambda_param, 1]\n",
    "        \n",
    "        registration_model.compile(optimizer='Adam', loss=losses, loss_weights=loss_weights)\n",
    "        \n",
    "        # =============================================================================\n",
    "        # Training loop\n",
    "        # =============================================================================\n",
    "        \n",
    "        f_path = 'nifti_data/train'#r'nifti_data/train'\n",
    "        #f_path = '/content/drive/MyDrive/nifti_data_smol/train'\n",
    "        \n",
    "        val_path = 'nifti_data/val'#r'nifti_data/val'\n",
    "        #val_path = '/content/drive/MyDrive/nifti_data_smol/val'\n",
    "        \n",
    "        model_save_path = 'DICE_2D_WS_US-MRI_NCC_checkpoints'#r'voxelmorph_model_checkpoints'\n",
    "        if not os.path.exists(model_save_path):\n",
    "            os.mkdir(model_save_path)\n",
    "        \n",
    "        batch_size = 32 # decrease this is you are running out of RAM\n",
    "    \n",
    "        # ------------------------------\n",
    "        # Resume from last checkpoint\n",
    "        # ------------------------------\n",
    "        if latest_weights is not None:\n",
    "            print(f\"Resuming from {latest_weights} (trial {last_trial})\")\n",
    "            registration_model.load_weights(latest_weights)\n",
    "            start_trial = last_trial + 1\n",
    "            trial_num = last_trial\n",
    "            # Load arrays\n",
    "            val_dice = np.load(os.path.join(model_save_path, \"val_dice.npy\")).tolist()\n",
    "            transformer_losses = np.load(os.path.join(model_save_path, \"transformer_losses.npy\")).tolist()\n",
    "            losses = np.load(os.path.join(model_save_path, \"losses.npy\")).tolist()\n",
    "            conv2d_losses = np.load(os.path.join(model_save_path, \"conv2d_losses.npy\")).tolist()\n",
    "            \n",
    "            # Index from 0 to trial_num\n",
    "            val_dice = val_dice[:trial_num + 1]\n",
    "            transformer_losses = transformer_losses[:trial_num + 1]\n",
    "            losses = losses[:trial_num + 1]\n",
    "            conv2d_losses = conv2d_losses[:trial_num + 1]\n",
    "        else:\n",
    "            print(\"No previous weights found, starting fresh\")\n",
    "            start_trial = 0\n",
    "            val_dice = []\n",
    "            losses = []\n",
    "            transformer_losses = []\n",
    "            conv2d_losses = []\n",
    "        \n",
    "        train_gen = train_generator_(f_path, batch_size, moving_image_shape, fixed_image_shape, with_label_inputs=True)\n",
    "        \n",
    "        num_trials = 1024\n",
    "         \n",
    "        for trial in range(start_trial, num_trials):\n",
    "            \n",
    "            print(f'\\nTrial {trial} / {num_trials-1}:')\n",
    "        \n",
    "            hist = registration_model.fit(train_gen, epochs=1, steps_per_epoch=32, verbose=1);#32, verbose=1);\n",
    "        \n",
    "            dice_scores = []\n",
    "        \n",
    "            count = 0\n",
    "            label_num = 0\n",
    "            val_gen = test_generator(val_path, 4, moving_image_shape, fixed_image_shape, start_index=None, end_index=None, label_num=label_num, with_label_inputs=True)\n",
    "            while True:\n",
    "                try:\n",
    "                    (val_inputs, val_outputs) = next(val_gen)\n",
    "                    moving_images_val, fixed_images_val, moving_labels_val, fixed_labels_val = val_inputs\n",
    "                    fixed_images_val, zero_phis_val, fixed_labels_val = val_outputs\n",
    "                    _, ddf_val, _ = registration_model.predict((moving_images_val, fixed_images_val, moving_labels_val, fixed_labels_val), verbose=0)\n",
    "        \n",
    "                    moved_labels_val = spatial_transformer([moving_labels_val, ddf_val])\n",
    "                    moved_images_val = spatial_transformer([moving_images_val, ddf_val])\n",
    "    \n",
    "                    if count ==0 and Verbose:\n",
    "                        # VISUALLY CHECK FIXED, MOVING MOVED IMAGES\n",
    "                        print(moving_images_val.shape)\n",
    "                        plt.subplot(1,3,1)\n",
    "                        plt.imshow(tf.squeeze(moved_images_val[0]), cmap='gray')\n",
    "                        plt.title('Moved Image')\n",
    "        \n",
    "                        plt.subplot(1,3,2)\n",
    "                        plt.imshow(tf.squeeze(moving_images_val[0]), cmap='gray')\n",
    "                        plt.title('Moving Image')\n",
    "        \n",
    "                        plt.subplot(1,3,3)\n",
    "                        plt.imshow(tf.squeeze(fixed_images_val[0]), cmap='gray')\n",
    "                        plt.title('Fixed Image')\n",
    "                        plt.show()\n",
    "    \n",
    "                        # VISUALLY CHECK LABELS\n",
    "                        plt.subplot(1,3,1)\n",
    "                        plt.imshow(tf.squeeze(moved_labels_val[0]), cmap='gray')\n",
    "                        plt.title('Moved Label')\n",
    "                        plt.subplot(1,3,2)\n",
    "                        plt.imshow(tf.squeeze(moving_labels_val[0]), cmap='gray')\n",
    "                        plt.title('Moving Label')\n",
    "                        plt.subplot(1,3,3)\n",
    "                        plt.imshow(tf.squeeze(fixed_labels_val[0]), cmap='gray')\n",
    "                        plt.title('Fixed Label')\n",
    "                        plt.show()\n",
    "    \n",
    "                        val_pred = tuple(ddf_val)\n",
    "                        flow = val_pred[1].squeeze()[::3,::3]\n",
    "                        print(\"ddf_val shape: \", ddf_val.shape)\n",
    "                        \n",
    "                        ddf_flow = np.stack([-ddf_val[0][..., 1], -ddf_val[0][..., 0]], axis=-1)\n",
    "                        ne.plot.flow([ddf_flow], width=5);\n",
    "                        count += 1\n",
    "        \n",
    "                    dice_score = np.array(-1.0 * vxm.losses.Dice().loss(tf.convert_to_tensor(moved_labels_val, dtype='float32'), tf.convert_to_tensor(fixed_labels_val, dtype='float32')))\n",
    "                    dice_scores.append(dice_score)\n",
    "                    print(\".\", end='')\n",
    "                except (IndexError, StopIteration) as e:\n",
    "                      break  \n",
    "                    \n",
    "            val_dice.append(np.mean(dice_scores))\n",
    "            if trial == 0:\n",
    "                losses.append(0)\n",
    "            else:\n",
    "                losses.append(hist.history[\"loss\"][0])\n",
    "            transformer_losses.append(hist.history[\"transformer_loss\"][0])\n",
    "            conv_loss_key = next(\n",
    "                (key for key in hist.history.keys() \n",
    "                 if key.startswith('conv2d_') and key.endswith('_loss')),\n",
    "                None\n",
    "            )\n",
    "            if trial == 0:\n",
    "                conv2d_losses.append(0)\n",
    "            else:\n",
    "                conv2d_losses.append(hist.history[conv_loss_key][0])\n",
    "            if Verbose:\n",
    "                plt.figure(figsize=(12, 4))\n",
    "                plt.subplot(1, 3, 1)\n",
    "                plt.subplots_adjust(wspace=0.5) \n",
    "                \n",
    "                plt.plot(losses, label=\"Loss\")\n",
    "                plt.plot(transformer_losses, label=\"Transformer Loss\")\n",
    "                plt.xlabel('Trials')\n",
    "                plt.ylabel('Losses')\n",
    "                plt.legend()\n",
    "        \n",
    "                plt.subplot(1, 3, 2)\n",
    "                plt.plot(conv2d_losses, label=\"Conv2D Loss\")\n",
    "                plt.xlabel('Trials')\n",
    "                plt.ylabel('Losses')\n",
    "                plt.legend()\n",
    "        \n",
    "                plt.subplot(1, 3, 3)\n",
    "                plt.plot(val_dice, 'r')\n",
    "                plt.xlabel('Trials')\n",
    "                plt.ylabel('Dice')\n",
    "                plt.savefig(r'voxelmorph_val_dice_1.png')\n",
    "                plt.show()\n",
    "            print('    Validation Dice: ', np.mean(dice_scores))\n",
    "    \n",
    "            np.save(os.path.join(model_save_path, \"losses.npy\"), np.array(losses))\n",
    "            np.save(os.path.join(model_save_path, \"transformer_losses.npy\"), np.array(transformer_losses))\n",
    "            np.save(os.path.join(model_save_path, \"conv2d_losses.npy\"), np.array(conv2d_losses))\n",
    "            np.save(os.path.join(model_save_path, \"val_dice.npy\"), np.array(val_dice))\n",
    "            print(\"Training history saved.\")\n",
    "            \n",
    "            if trial % 8 == 0:\n",
    "              print(\"Saving Weights:\")\n",
    "              save_path = os.path.join(model_save_path, f\"weights_trial_{trial}.weights.h5\")\n",
    "              registration_model.save_weights(save_path)\n",
    "              print(f\"Weights saved to {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c4d7d9-8730-4f24-92b7-b3d062b304ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(Verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7951473f-b775-4fea-8f1b-8bc38deb60e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(0, '2D_WS_US-MRI_NCC_checkpoints/weights_trial_0.weights.h5', Verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f890a639-e4c2-42f4-88f6-e75d15ae4e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(Verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fb0696-147f-4178-bf5e-b606a8cfc31a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
