{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c563be7b-87f9-4947-9db4-245f3b564cce",
   "metadata": {},
   "source": [
    "# Hypothesis 1, Part 1: Running Unsupervised Model with MSE and NCC with No Affine Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071254eb-fa98-4a52-b838-4cfc153e9ca8",
   "metadata": {},
   "source": [
    "- In order to determine if label-driven approaches are required, we must experiment with models with loss functions driven by regularisation and similarity metrics\n",
    "- Here, we run models using MSE and NCC using the literature recommended hyperparameters to demonstrate how useless they are by themselves. No affine prepocessing is used at first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e261d8f7-4195-42ad-b41e-98d7584d43d4",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5841c0e5-1f2b-4ecd-9268-d264e97ea9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # imports\n",
    "# import os, sys\n",
    "\n",
    "# # third party imports\n",
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "# assert tf.__version__.startswith('2.'), 'This tutorial assumes Tensorflow 2.0+'\n",
    "\n",
    "# # local imports\n",
    "# import voxelmorph as vxm\n",
    "# import neurite as ne\n",
    "# imports\n",
    "import os, sys\n",
    "\n",
    "# third party imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "assert tf.__version__.startswith('2.'), 'This tutorial assumes Tensorflow 2.0+'\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "\n",
    "# local imports\n",
    "import voxelmorph as vxm\n",
    "import neurite as ne\n",
    "\n",
    "\n",
    "from skimage.transform import resize\n",
    "import nibabel as nib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os, re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import SimpleITK as sitk\n",
    "import csv\n",
    "\n",
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from scipy.ndimage import _ni_support\n",
    "from scipy.ndimage import generate_binary_structure, distance_transform_edt, binary_erosion\n",
    "\n",
    "#from data_generator import resize_3d_image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67991ec-6603-4ba9-adf4-6dd80297344d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_experiments(name, intensity_metric, weakly_supervised, train_path, val_path ,Verbose=False):\n",
    "    # ======================================\n",
    "    # BUILD MODEL ARCHITECTURE\n",
    "    # ======================================\n",
    "    \n",
    "    from tensorflow.keras import layers\n",
    "    from tensorflow import keras\n",
    "    \n",
    "    def get_model(moving_image_shape, fixed_image_shape, with_label_inputs=True, up_filters=[64, 128, 256], down_filters=[256, 128, 64, 32]):\n",
    "    \n",
    "        input_moving_image = keras.Input(moving_image_shape)\n",
    "        input_fixed_image = keras.Input(fixed_image_shape)\n",
    "    \n",
    "        if with_label_inputs:\n",
    "            input_moving_label = keras.Input(moving_image_shape)\n",
    "            input_fixed_label = keras.Input(fixed_image_shape)\n",
    "    \n",
    "        concatenate_layer = layers.Concatenate(axis=-1)([input_moving_image, input_fixed_image])\n",
    "    \n",
    "        ### [First half of the network: downsampling inputs] ###\n",
    "    \n",
    "        # Entry block\n",
    "        x = layers.Conv3D(32, 3, strides=2, padding=\"same\")(concatenate_layer)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "    \n",
    "        previous_block_activation = x  # Set aside residual\n",
    "    \n",
    "        # Blocks 1, 2, 3 are identical apart from the feature depth.\n",
    "        for filters in up_filters:\n",
    "            x = layers.Activation(\"relu\")(x)\n",
    "            x = layers.Conv3D(filters, 3, padding=\"same\")(x)\n",
    "            x = layers.BatchNormalization()(x)\n",
    "    \n",
    "            x = layers.Activation(\"relu\")(x)\n",
    "            x = layers.Conv3D(filters, 3, padding=\"same\")(x)\n",
    "            x = layers.BatchNormalization()(x)\n",
    "    \n",
    "            x = layers.MaxPooling3D(3, strides=2, padding=\"same\")(x)\n",
    "    \n",
    "            # Project residual\n",
    "            residual = layers.Conv3D(filters, 1, strides=2, padding=\"same\")(\n",
    "                previous_block_activation\n",
    "            )\n",
    "            x = layers.add([x, residual])  # Add back residual\n",
    "            previous_block_activation = x  # Set aside next residual\n",
    "    \n",
    "        ### [Second half of the network: upsampling inputs] ###\n",
    "    \n",
    "        for filters in down_filters:\n",
    "            x = layers.Activation(\"relu\")(x)\n",
    "            x = layers.Conv3DTranspose(filters, 3, padding=\"same\")(x)\n",
    "            x = layers.BatchNormalization()(x)\n",
    "    \n",
    "            x = layers.Activation(\"relu\")(x)\n",
    "            x = layers.Conv3DTranspose(filters, 3, padding=\"same\")(x)\n",
    "            x = layers.BatchNormalization()(x)\n",
    "    \n",
    "            x = layers.UpSampling3D(2)(x)\n",
    "    \n",
    "            # Project residual\n",
    "            residual = layers.UpSampling3D(2)(previous_block_activation)\n",
    "            residual = layers.Conv3D(filters, 1, padding=\"same\")(residual)\n",
    "            x = layers.add([x, residual])  # Add back residual\n",
    "            previous_block_activation = x  # Set aside next residual\n",
    "    \n",
    "        # Add a per-pixel classification layer\n",
    "        out_ddf = layers.Conv3D(3, 3, activation=\"linear\", padding=\"same\")(x)\n",
    "    \n",
    "        # Define the model\n",
    "        if with_label_inputs:\n",
    "            model = keras.Model(inputs=[input_moving_image, input_fixed_image, input_moving_label, input_fixed_label], outputs=[out_ddf])\n",
    "        else:\n",
    "            model = keras.Model(inputs=[input_moving_image, input_fixed_image], outputs=[out_ddf])\n",
    "        return model\n",
    "    \n",
    "    # ======================================\n",
    "    # CACHE RELEVENT DATA\n",
    "    # ======================================\n",
    "    \n",
    "    def resize_3d_image(image, shape):\n",
    "        resized_image = resize(image, output_shape=shape)\n",
    "        if np.amax(resized_image) == np.amin(resized_image):\n",
    "            normalised_image = resized_image\n",
    "        else:\n",
    "            normalised_image = (resized_image-np.amin(resized_image))/(np.amax(resized_image)-np.amin(resized_image))\n",
    "        return normalised_image\n",
    "    \n",
    "    def load_dataset_into_cache(f_path, moving_image_shape, fixed_image_shape, with_label_inputs=True):\n",
    "        moving_images_path = os.path.join(f_path, 'us_images')\n",
    "        fixed_images_path = os.path.join(f_path, 'mr_images')\n",
    "    \n",
    "        all_names = np.array(os.listdir(fixed_images_path))\n",
    "    \n",
    "        cache = {}\n",
    "    \n",
    "        for f_name in all_names:\n",
    "            moving_image = nib.load(os.path.join(moving_images_path, f_name)).get_fdata()\n",
    "            fixed_image = nib.load(os.path.join(fixed_images_path, f_name)).get_fdata()\n",
    "    \n",
    "            moving_image_resized = resize_3d_image(moving_image, moving_image_shape)\n",
    "            fixed_image_resized = resize_3d_image(fixed_image, fixed_image_shape)\n",
    "    \n",
    "            entry = {\n",
    "                \"moving\": moving_image_resized,\n",
    "                \"fixed\": fixed_image_resized,\n",
    "            }\n",
    "    \n",
    "            if with_label_inputs:\n",
    "                moving_labels_path = os.path.join(f_path, 'us_labels')\n",
    "                fixed_labels_path = os.path.join(f_path, 'mr_labels')\n",
    "    \n",
    "                moving_label = nib.load(os.path.join(moving_labels_path, f_name)).get_fdata()\n",
    "                fixed_label = nib.load(os.path.join(fixed_labels_path, f_name)).get_fdata()\n",
    "    \n",
    "                entry[\"moving_label\"] = moving_label\n",
    "                entry[\"fixed_label\"] = fixed_label\n",
    "    \n",
    "            cache[f_name] = entry\n",
    "    \n",
    "        return cache\n",
    "    \n",
    "    # =========================================\n",
    "    # DEFINING THE SHAPES WE ARE WORKING WITH\n",
    "    # =========================================\n",
    "    \n",
    "    moving_image_shape = (64, 64, 64, 1)\n",
    "    fixed_image_shape = (64, 64, 64, 1)\n",
    "    \n",
    "    # train_cache = load_dataset_into_cache(\"nifti_data_preprocessed/train\", moving_image_shape, moving_image_shape, with_label_inputs=True)\n",
    "    # test_cache = load_dataset_into_cache(\"nifti_data_preprocessed/val\", moving_image_shape, moving_image_shape, with_label_inputs=True)\n",
    "    train_cache = load_dataset_into_cache(train_path, moving_image_shape, moving_image_shape, with_label_inputs=True)\n",
    "    test_cache = load_dataset_into_cache(val_path, moving_image_shape, moving_image_shape, with_label_inputs=True)\n",
    "    \n",
    "    # =========================================\n",
    "    # TRAIN AND TEST GEN\n",
    "    # =========================================\n",
    "    \n",
    "    \n",
    "    def train_generator_(cache, batch_size, moving_image_shape, fixed_image_shape, with_label_inputs=True):\n",
    "        \n",
    "        all_names = list(cache.keys())\n",
    "    \n",
    "        while True:\n",
    "            batch_names = np.random.permutation(all_names)[:batch_size]\n",
    "    \n",
    "            moving_images_batch = np.zeros((batch_size, *moving_image_shape))\n",
    "            fixed_images_batch = np.zeros((batch_size, *fixed_image_shape))\n",
    "    \n",
    "            if with_label_inputs:\n",
    "                moving_labels_batch = np.zeros((batch_size, *moving_image_shape))\n",
    "                fixed_labels_batch = np.zeros((batch_size, *fixed_image_shape))\n",
    "    \n",
    "            for i, f_name in enumerate(batch_names):\n",
    "                entry = cache[f_name]\n",
    "                moving = entry[\"moving\"]\n",
    "                fixed  = entry[\"fixed\"]\n",
    "    \n",
    "                if with_label_inputs:\n",
    "                    label_to_select = np.random.randint(6)\n",
    "                    moving_label = resize_3d_image(entry[\"moving_label\"][:, :, :, label_to_select], moving_image_shape)\n",
    "                    fixed_label  = resize_3d_image(entry[\"fixed_label\"][:, :, :, label_to_select], fixed_image_shape)\n",
    "                else:\n",
    "                    moving_label, fixed_label = None, None\n",
    "    \n",
    "                # assign into batch\n",
    "                moving_images_batch[i] = moving\n",
    "                fixed_images_batch[i]  = fixed\n",
    "                if with_label_inputs:\n",
    "                    moving_labels_batch[i] = moving_label\n",
    "                    fixed_labels_batch[i]  = fixed_label\n",
    "    \n",
    "            zero_phis = np.zeros([batch_size, *moving_image_shape[:-1], 3])\n",
    "    \n",
    "            if with_label_inputs:\n",
    "                inputs = (moving_images_batch, fixed_images_batch, moving_labels_batch, fixed_labels_batch)\n",
    "                outputs = (fixed_images_batch, zero_phis, fixed_labels_batch)\n",
    "            else:\n",
    "                inputs = (moving_images_batch, fixed_images_batch)\n",
    "                outputs = (fixed_images_batch, zero_phis)\n",
    "    \n",
    "            yield inputs, outputs\n",
    "    \n",
    "    \n",
    "    \n",
    "    def test_generator(cache, batch_size, moving_image_shape, fixed_image_shape, start_index, end_index, label_num, with_label_inputs=True):\n",
    "        all_names = list(cache.keys())[start_index:end_index]\n",
    "        n_steps = int(np.floor(len(all_names) / batch_size))\n",
    "    \n",
    "        for step in range(n_steps):\n",
    "            batch_names = all_names[step*batch_size:(step+1)*batch_size]\n",
    "    \n",
    "            moving_images_batch = np.zeros((batch_size, *moving_image_shape))\n",
    "            fixed_images_batch = np.zeros((batch_size, *fixed_image_shape))\n",
    "    \n",
    "            if with_label_inputs:\n",
    "                moving_labels_batch = np.zeros((batch_size, *moving_image_shape))\n",
    "                fixed_labels_batch = np.zeros((batch_size, *fixed_image_shape))\n",
    "    \n",
    "            for i, f_name in enumerate(batch_names):\n",
    "                entry = cache[f_name]\n",
    "                moving_images_batch[i] = entry[\"moving\"]\n",
    "                fixed_images_batch[i] = entry[\"fixed\"]\n",
    "    \n",
    "                if with_label_inputs:\n",
    "                    moving_labels_batch[i] = resize_3d_image(entry[\"moving_label\"][:, :, :, label_num], moving_image_shape)\n",
    "                    fixed_labels_batch[i] = resize_3d_image(entry[\"fixed_label\"][:, :, :, label_num], fixed_image_shape)\n",
    "    \n",
    "            zero_phis = np.zeros([batch_size, *moving_image_shape[:-1], 3])\n",
    "    \n",
    "            if with_label_inputs:\n",
    "                inputs = [moving_images_batch, fixed_images_batch, moving_labels_batch, fixed_labels_batch]\n",
    "                outputs = [fixed_images_batch, zero_phis, fixed_labels_batch]\n",
    "            else:\n",
    "                inputs = [moving_images_batch, fixed_images_batch]\n",
    "                outputs = [fixed_images_batch, zero_phis]\n",
    "    \n",
    "            yield inputs, outputs\n",
    "    \n",
    "    \n",
    "    # ==============================================\n",
    "    # TRAINING LOOP\n",
    "    # ==============================================\n",
    "    \n",
    "    \n",
    "    os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    def train_model(similarity_metric, weak_supervision, last_trial=None, latest_weights=None, Verbose=False):\n",
    "        model_save_path = f'H1_Experiments/{name}_Part_1_Checkpoints_More_Epochs'\n",
    "        if not os.path.exists(model_save_path):\n",
    "            os.mkdir(model_save_path)\n",
    "        \n",
    "        for lambda_param in [0.1]: # incase you want to tune the regularization scalar\n",
    "            \n",
    "            # =============================================================================\n",
    "            # Build the backbone model\n",
    "            # =============================================================================\n",
    "            \n",
    "            moving_image_shape = (64, 64, 64, 1)\n",
    "            fixed_image_shape = (64, 64, 64, 1)\n",
    "            \n",
    "            model = get_model(moving_image_shape, fixed_image_shape, with_label_inputs=False)\n",
    "            \n",
    "            print('\\nBackbone model inputs and outputs:')\n",
    "            \n",
    "            print('    input shape: ', ', '.join([str(t.shape) for t in model.inputs]))\n",
    "            print('    output shape:', ', '.join([str(t.shape) for t in model.outputs]))\n",
    "            \n",
    "            # =============================================================================\n",
    "            # Build the registration network\n",
    "            # =============================================================================\n",
    "            \n",
    "            # build transformer layer\n",
    "            spatial_transformer = vxm.layers.SpatialTransformer(name='transformer')\n",
    "            \n",
    "            # extract the moving image\n",
    "            moving_image = model.input[0]\n",
    "            fixed_image = model.inputs[1]\n",
    "            input_moving_label = keras.Input(moving_image_shape, name=\"moving_label\")\n",
    "            input_fixed_label  = keras.Input(fixed_image_shape,  name=\"fixed_label\")\n",
    "            inputs=[moving_image, fixed_image, input_moving_label, input_fixed_label]\n",
    "            \n",
    "            # extract ddf\n",
    "            ddf = model.outputs[0]\n",
    "            \n",
    "            # warp the moving image with the transformer using network-predicted ddf\n",
    "            moved_image = spatial_transformer([moving_image, ddf])\n",
    "            moved_label = spatial_transformer([input_moving_label, ddf])\n",
    "            fixed_label = spatial_transformer([input_moving_label, ddf])*0 + input_fixed_label # This is a hacky way of making keras stop complaining about inputs not connected to outputs\n",
    "            \n",
    "            outputs = [moved_image, ddf, moved_label]\n",
    "            \n",
    "            registration_model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "            \n",
    "            print('\\nRegistration network inputs and outputs:')\n",
    "            \n",
    "            print('    input shape: ', ', '.join([str(t.shape) for t in registration_model.inputs]))\n",
    "            print('    output shape:', ', '.join([str(t.shape) for t in registration_model.outputs]))\n",
    "    \n",
    "            if similarity_metric == \"NCC\" and weak_supervision == False:\n",
    "                losses = [vxm.losses.NCC().loss, vxm.losses.Grad('l2').loss, vxm.losses.Dice().loss]\n",
    "                loss_weights = [1, lambda_param, 0]\n",
    "            elif similarity_metric == \"NCC\" and weak_supervision == True:\n",
    "                losses = [vxm.losses.NCC().loss, vxm.losses.Grad('l2').loss, vxm.losses.Dice().loss]\n",
    "                loss_weights = [0, lambda_param, 1]\n",
    "            elif similarity_metric == \"MSE\" and weak_supervision == False:\n",
    "                losses = [vxm.losses.MSE().loss, vxm.losses.Grad('l2').loss, vxm.losses.Dice().loss]\n",
    "                loss_weights = [0, lambda_param, 0]\n",
    "            elif similarity_metric == \"MSE\" and weak_supervision == True:\n",
    "                losses = [vxm.losses.MSE().loss, vxm.losses.Grad('l2').loss, vxm.losses.Dice().loss]\n",
    "                loss_weights = [1, lambda_param, 1]\n",
    "            \n",
    "            registration_model.compile(optimizer='Adam', loss=losses, loss_weights=loss_weights)\n",
    "    \n",
    "            # =========================================================================\n",
    "            # Resume from last trial\n",
    "            # =========================================================================\n",
    "    \n",
    "            if latest_weights is not None:\n",
    "                print(f\"Resuming from {latest_weights} (trial {last_trial})\")\n",
    "                registration_model.load_weights(latest_weights)\n",
    "                start_trial = last_trial + 1\n",
    "    \n",
    "                # Load arrays\n",
    "                val_dice = np.load(os.path.join(model_save_path, \"val_dice.npy\")).tolist()\n",
    "                transformer_losses = np.load(os.path.join(model_save_path, \"transformer_losses.npy\")).tolist()\n",
    "                losses = np.load(os.path.join(model_save_path, \"losses.npy\")).tolist()\n",
    "                conv3d_losses = np.load(os.path.join(model_save_path, \"conv3d_losses.npy\")).tolist()\n",
    "                \n",
    "                # Index from 0 to trial_num\n",
    "                val_dice = val_dice[:last_trial + 1]\n",
    "                transformer_losses = transformer_losses[:last_trial + 1]\n",
    "                losses = losses[:last_trial + 1]\n",
    "                conv3d_losses = conv3d_losses[:last_trial +1]\n",
    "            \n",
    "            else:\n",
    "                print(\"No previous weights found, starting fresh\")\n",
    "                start_trial = 0\n",
    "                val_dice = []\n",
    "                losses = []\n",
    "                transformer_losses = []\n",
    "                conv3d_losses = []\n",
    "            \n",
    "            # =============================================================================\n",
    "            # Training loop\n",
    "            # =============================================================================\n",
    "            \n",
    "            batch_size = 8 # Decrease this if you are running out of RAM - set to 4, 8, 16 ect.\n",
    "            \n",
    "            train_gen = train_generator_(train_cache, batch_size, moving_image_shape, fixed_image_shape, with_label_inputs=True)\n",
    "            \n",
    "            num_trials = 1024 # This may be way above what we require\n",
    "            \n",
    "            for trial in range(start_trial, num_trials):\n",
    "                print(f'\\nTrial {trial} / {num_trials-1}:')\n",
    "            \n",
    "                hist = registration_model.fit(train_gen, epochs=1, steps_per_epoch=32, verbose=1);\n",
    "    \n",
    "                dice_scores = []\n",
    "                \n",
    "                for label_num in range(6):\n",
    "                    val_gen = test_generator(test_cache, 4, moving_image_shape, fixed_image_shape, start_index=None, end_index=None, label_num=label_num, with_label_inputs=True)\n",
    "                    val_count = 0\n",
    "                    while True:\n",
    "                        try:\n",
    "                            (val_inputs, val_outputs) = next(val_gen)\n",
    "                            moving_images_val, fixed_images_val, moving_labels_val, fixed_labels_val = val_inputs\n",
    "                            fixed_images_val, zero_phis_val, fixed_labels_val = val_outputs\n",
    "                            _, ddf_val, _ = registration_model.predict((moving_images_val, fixed_images_val, moving_labels_val, fixed_labels_val), verbose=0)\n",
    "            \n",
    "                            moved_labels_val = spatial_transformer([moving_labels_val, ddf_val])\n",
    "                            moved_images_val = spatial_transformer([moving_images_val, ddf_val])\n",
    "            \n",
    "                            if label_num == 0 and val_count == 0:\n",
    "                                # Moving, moved and fixed image slice indices\n",
    "                                slice_index_moving = 32#moving_images_val.shape[0] // 2\n",
    "                                slice_index_fixed = 32#fixed_images_val.shape[0] // 2\n",
    "                                print(\"-\",moving_images_val.shape)\n",
    "                                moving_images_val_slice = tf.squeeze(moving_images_val[0])[slice_index_moving,:,:]\n",
    "                                fixed_images_val_slice = tf.squeeze(fixed_images_val[0])[slice_index_fixed,:,:]\n",
    "                                moved_images_val_slice = tf.squeeze(moved_images_val[0])[slice_index_moving,:,:]\n",
    "                \n",
    "                                # Moving, moved and fixed label slice indices\n",
    "                                slice_index_moving = 32#moving_labels_val.shape[0] // 2\n",
    "                                slice_index_fixed = 32#fixed_labels_val.shape[0] // 2\n",
    "                                moving_labels_val_slice = tf.squeeze(moving_labels_val[0])[slice_index_moving,:,:]\n",
    "                                fixed_labels_val_slice = tf.squeeze(fixed_labels_val[0])[slice_index_fixed,:,:]\n",
    "                                moved_labels_val_slice = tf.squeeze(moved_labels_val[0])[slice_index_moving,:,:]\n",
    "                \n",
    "                                # VISUALLY CHECK FIXED, MOVING MOVED IMAGES\n",
    "                                print(\"*\", tf.squeeze(moved_images_val_slice).shape)\n",
    "                                print(moving_images_val.shape)\n",
    "                                plt.subplot(1,3,1)\n",
    "                                plt.imshow(tf.squeeze(moved_images_val_slice), cmap='gray')\n",
    "                                plt.title('Moved Image')\n",
    "                \n",
    "                                plt.subplot(1,3,2)\n",
    "                                plt.imshow(tf.squeeze(moving_images_val_slice), cmap='gray')\n",
    "                                plt.title('Moving Image')\n",
    "                \n",
    "                                plt.subplot(1,3,3)\n",
    "                                plt.imshow(tf.squeeze(fixed_images_val_slice), cmap='gray')\n",
    "                                plt.title('Fixed Image')\n",
    "                                # plt.show()\n",
    "                                save_name_img = os.path.join(model_save_path, f\"image_slices_trial_{trial}.png\")\n",
    "                                plt.savefig(save_name_img, dpi=300, bbox_inches='tight')\n",
    "                                plt.show()\n",
    "                                plt.close()\n",
    "                                print(f\"Saved image slices to {save_name_img}\")\n",
    "                \n",
    "                                # VISUALLY CHECK LABELS\n",
    "                                plt.subplot(1,3,1)\n",
    "                                plt.imshow(tf.squeeze(moved_labels_val_slice), cmap='gray')\n",
    "                                plt.title('Moved Label')\n",
    "                                \n",
    "                                plt.subplot(1,3,2)\n",
    "                                plt.imshow(tf.squeeze(moving_labels_val_slice), cmap='gray')\n",
    "                                plt.title('Moving Label')\n",
    "                                \n",
    "                                plt.subplot(1,3,3)\n",
    "                                plt.imshow(tf.squeeze(fixed_labels_val_slice), cmap='gray')\n",
    "                                plt.title('Fixed Label')\n",
    "                                # plt.show()\n",
    "                                save_name_lbl = os.path.join(model_save_path, f\"label_slices_trial_{trial}.png\")\n",
    "                                plt.savefig(save_name_lbl, dpi=300, bbox_inches='tight')\n",
    "                                plt.show()\n",
    "                                plt.close()\n",
    "                                print(f\"Saved label slices to {save_name_lbl}\")\n",
    "            \n",
    "                                ddf = ddf_val[1].squeeze()  # Remove batch/channel dims -> (64, 64, 64, 3)\n",
    "                                mid_z = ddf.shape[0] // 2\n",
    "                                mid_plane = ddf[mid_z, :, :, :]  # Take middle z-slice -> (64, 64, 3)\n",
    "                                \n",
    "                                # Downsample for cleaner visualization\n",
    "                                flow = mid_plane[::1, ::1]  # Downsample to (21, 21, 3) if you want. I don't downsample at all\n",
    "                                \n",
    "                                # Visualize (showing x,y components only - drop z-component for 2D plot)\n",
    "                                #flow = np.stack([-flow[0][..., 1], -flow[0][..., 0]], axis=-1)\n",
    "                                \n",
    "                                # plt.figure(figsize=(6,6))\n",
    "                                #ne.plot.flow([flow[..., :2]], width=5);  # Only show x,y vectors\n",
    "                                # save_name_flow = os.path.join(model_save_path, f\"flow_field_trial_{trial}.png\")\n",
    "                                # plt.savefig(save_name_flow, dpi=300, bbox_inches='tight')\n",
    "                                # plt.close()\n",
    "                                # print(f\"Saved flow field to {save_name_flow}\")\n",
    "                                ddf = ddf_val[0].squeeze()  # Remove batch/channel dims -> (64, 64, 64, 3) # WAS 1\n",
    "                                mid_z = ddf.shape[0] // 2\n",
    "                                mid_plane = ddf[mid_z, :, :, :]  # Take middle z-slice -> (64, 64, 3)\n",
    "                                \n",
    "                                # Downsample for cleaner visualization\n",
    "                                flow = mid_plane[::1, ::1]  # Downsample to (21, 21, 3)\n",
    "                                \n",
    "                                # Visualize (showing x,y components only - drop z-component for 2D plot)\n",
    "                                #flow = np.stack([-flow[0][..., 1], -flow[0][..., 0]], axis=-1)\n",
    "                                ne.plot.flow([flow[..., :2]], width=5);  # Only show x,y vectors\n",
    "        \n",
    "                                val_count += 1\n",
    "                            \n",
    "                            dice_score = np.array(-1.0 * vxm.losses.Dice().loss(tf.convert_to_tensor(moved_labels_val, dtype='float32'), tf.convert_to_tensor(fixed_labels_val, dtype='float32')))\n",
    "                            dice_scores.append(dice_score)\n",
    "\n",
    "                            print('.', end='')\n",
    "                        except (IndexError, StopIteration) as e:\n",
    "                            break\n",
    "    \n",
    "                values = [arr.item() for arr in dice_scores]\n",
    "                print(values)\n",
    "                losses.append(hist.history[\"loss\"][0])\n",
    "                transformer_losses.append(hist.history[\"transformer_loss\"][0])\n",
    "                conv_loss_key = next(\n",
    "                    (key for key in hist.history.keys() \n",
    "                     if key.startswith('conv3d_') and key.endswith('_loss')),\n",
    "                    None\n",
    "                )                \n",
    "                conv3d_losses.append(hist.history[conv_loss_key][0]) \n",
    "                val_dice.append(np.mean(dice_scores))\n",
    "        \n",
    "                if True:\n",
    "                    plt.figure(figsize=(12, 4))\n",
    "                    plt.subplot(1, 3, 1)\n",
    "                    plt.subplots_adjust(wspace=0.5) \n",
    "                    \n",
    "                    plt.plot(losses, label=\"Total Loss\")\n",
    "                    plt.plot(transformer_losses, label=\"Regularization Loss\")\n",
    "                    plt.xlabel('Trials')\n",
    "                    plt.ylabel('Losses')\n",
    "                    plt.legend()  \n",
    "            \n",
    "                    plt.subplot(1, 3, 2)\n",
    "                    plt.plot(conv3d_losses, label=\"Regularization Loss\")\n",
    "                    plt.xlabel('Trials')\n",
    "                    plt.ylabel('Losses')\n",
    "                    plt.legend()  \n",
    "                                         \n",
    "                    plt.subplot(1, 3, 3)\n",
    "                    plt.plot(val_dice, 'r')\n",
    "                    plt.xlabel('Trials')\n",
    "                    plt.ylabel('Dice')\n",
    "                    #plt.savefig(r'voxelmorph_val_dice_1.png')\n",
    "                    #plt.show()\n",
    "                    # Save figure with unique filename\n",
    "                    save_name = os.path.join(model_save_path, f\"training_curves_trial_{trial}.png\")\n",
    "                    plt.savefig(save_name, dpi=300, bbox_inches='tight')\n",
    "                    plt.close()\n",
    "                    print(f\"Saved plot to {save_name}\")\n",
    "                \n",
    "                print('    Validation Dice: ', np.mean(dice_scores))\n",
    "                    \n",
    "    train_model(intensity_metric,weakly_supervised,Verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221fe8cc-ee14-418b-bf2e-0f55247d8411",
   "metadata": {},
   "outputs": [],
   "source": [
    "for weak_supervision in [[True,\"unsupervised\"]]:\n",
    "    for intensity_metric in [\"NCC\"]:\n",
    "        for data in [[\"nifti_data_preprocessed/train\", \"nifti_data_preprocessed/val\"], [\"nifti_data/train\", \"nifti_data/val\"]]:\n",
    "        \n",
    "            if data[0] == \"nifti_data/train\":\n",
    "                name = f\"{intensity_metric}_{weak_supervision[1]}_no_preprocessing\"\n",
    "            elif data[0] == \"nifti_data_preprocessed/train\":\n",
    "                name = f\"{intensity_metric}_{weak_supervision[1]}_affine_preprocessing\"\n",
    "                \n",
    "            run_experiments(name,intensity_metric, weak_supervision[0], data[0], data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9d42b7-07cb-4885-bc2a-49ce11ffdcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for weak_supervision in [[True,\"unsupervised\"]]:\n",
    "    for intensity_metric in [\"NCC\"]:\n",
    "        for data in [[\"nifti_data/train\", \"nifti_data/val\"]]:\n",
    "        \n",
    "            if data[0] == \"nifti_data/train\":\n",
    "                name = f\"{intensity_metric}_{weak_supervision[1]}_no_preprocessing\"\n",
    "            elif data[0] == \"nifti_data_preprocessed/train\":\n",
    "                name = f\"{intensity_metric}_{weak_supervision[1]}_affine_preprocessing\"\n",
    "                \n",
    "            run_experiments(name,intensity_metric, weak_supervision[0], data[0], data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777ab1af-bea8-402e-a776-8ee76ed33d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "for weak_supervision in [[False,\"unsupervised\"]]:\n",
    "    for intensity_metric in [\"NCC\"]:\n",
    "        for data in [[\"nifti_data/train\", \"nifti_data/val\"]]:\n",
    "        \n",
    "            if data[0] == \"nifti_data/train\":\n",
    "                name = f\"{intensity_metric}_{weak_supervision[1]}_no_preprocessing\"\n",
    "            elif data[0] == \"nifti_data_preprocessed/train\":\n",
    "                name = f\"{intensity_metric}_{weak_supervision[1]}_affine_preprocessing\"\n",
    "                \n",
    "            run_experiments(name,intensity_metric, weak_supervision[0], data[0], data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a9fc1d-4f93-456f-a360-8aa05c668180",
   "metadata": {},
   "outputs": [],
   "source": [
    "for weak_supervision in [[False,\"unsupervised\"]]:\n",
    "    for intensity_metric in [\"NCC\"]:\n",
    "        for data in [[\"nifti_data/train\", \"nifti_data/val\"], [\"nifti_data_preprocessed/train\", \"nifti_data_preprocessed/val\"]]:\n",
    "        \n",
    "            if data[0] == \"nifti_data/train\":\n",
    "                name = f\"{intensity_metric}_{weak_supervision[1]}_no_preprocessing\"\n",
    "            elif data[0] == \"nifti_data_preprocessed/train\":\n",
    "                name = f\"{intensity_metric}_{weak_supervision[1]}_affine_preprocessing\"\n",
    "                \n",
    "            run_experiments(name,intensity_metric, weak_supervision[0], data[0], data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb57f6c8-4e84-47d6-8cab-1a95e391fc1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85a2b59-fbea-443c-a2fa-7f4b5cf4200e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
